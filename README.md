# Ф Quipu AI: Sistema RAG Multimodal Local

![Python](https://img.shields.io/badge/Python-3.11-blue?logo=python)
![Docker](https://img.shields.io/badge/Docker-v24+-2496ED?logo=docker)
![Architecture](https://img.shields.io/badge/Architecture-RAG-orange)
![License](https://img.shields.io/badge/License-MIT-green)

**Quipu AI** es una plataforma de ingenier铆a de software dise帽ada para la gesti贸n del conocimiento auditivo. Implementa una arquitectura **RAG (Retrieval-Augmented Generation)** ejecutada 100% *On-Premise* (local), garantizando privacidad total.

El sistema transforma datos no estructurados (audio/video) en conocimiento consultable, integrando modelos de vanguardia como **Whisper** (STT), **Llama 3.2** (LLM) y **Edge-TTS**.

---

## Arquitectura del Sistema

El flujo de datos sigue un pipeline ETL (Extract, Transform, Load) seguido de inferencia generativa:

```mermaid
graph TD
    A[Input: MP3 / YouTube] -->|Descarga & Conversi贸n| B(FFmpeg Processor)
    B -->|Inferencia STT| C{OpenAI Whisper}
    C -->|Transcripci贸n + Metadata| D[Base de Conocimiento .TXT]
    
    User[Usuario] -->|Consulta| E[Interfaz Streamlit]
    E -->|Selecci贸n de Contexto| D
    D -->|RAG: Contexto + Prompt| F[Ollama / Llama 3.2]
    F -->|Respuesta Texto| E
    F -->|S铆ntesis Neural| G[Edge TTS]
    G -->|Audio Output| User

```

---

## Funcionalidades Clave

### 1. N煤cleo RAG (Retrieval-Augmented Generation)

* **Ingesta Multifuente:** Soporta archivos locales (`.mp3`, `.wav`) y enlaces directos de YouTube (v铆a `yt-dlp`).
* **Memoria Selectiva:** Sistema de filtrado din谩mico que permite al usuario activar/desactivar documentos espec铆ficos del "cerebro" de la IA antes de realizar una consulta.

### 2. Interfaz Multimodal

* **Entrada:** Chat de texto.
* **Salida:** Texto enriquecido (Markdown) y Voz Neural de alta fidelidad.
* **Voces Regionales:** Soporte nativo para acentos de **Colombia** (`es-CO`), **Per煤** (`es-PE`), **M茅xico** (`es-MX`) y **Espa帽a** (`es-ES`).

### 3. Infraestructura Portable

* **Dockerizado:** Contenedor optimizado basado en Linux Debian (Python 3.11-slim) con FFmpeg preconfigurado.
* **Acceso Remoto:** Configuraci贸n lista para tunelizaci贸n v铆a **Ngrok**, permitiendo acceso desde dispositivos m贸viles.

---

## Gu铆a de Despliegue

### Opci贸n A: Producci贸n (Docker) - Recomendado

Despliegue agn贸stico del sistema operativo.

1. **Prerrequisitos:** Docker Desktop + Ollama (`ollama serve` en el host).
2. **Build & Run:**
```bash
docker build -t quipu-ai .
# El flag -e OLLAMA_HOST conecta el contenedor con el LLM del anfitri贸n
docker run -p 8501:8501 -e OLLAMA_HOST=[http://host.docker.internal:11434](http://host.docker.internal:11434) quipu-ai

```


3. **Acceso:** `http://localhost:8501`

### Opci贸n B: Desarrollo (Local Python)

Para editar c贸digo fuente.

1. **Instalar dependencias:**
```bash
pip install -r requerimientos.txt

```


2. **Ejecutar Suite:**
```bash
streamlit run web_app_master.py

```



---

## Herramientas CLI (Modo Avanzado)

El repositorio incluye scripts independientes para tareas por lotes (Batch Processing) sin usar la interfaz web:

| Script | Funci贸n | Comando |
| --- | --- | --- |
| `transcribir_pro.py` | Transcribe **todos** los audios de la carpeta actual y genera `.txt` con timestamps. Ideal para procesar 10+ archivos de golpe. | `python transcribir_pro.py` |
| `descargar_yt.py` | Descargador puro de audio YouTube (MP3 Alta Calidad) sin transcripci贸n. | `python descargar_yt.py` |
| `tts_manager.py` | M贸dulo de pruebas para s铆ntesis de voz y verificaci贸n de audio. | `python tts_manager.py` |

---

## Soluci贸n de Problemas (Troubleshooting)

**1. Error: `FFmpeg not found**`

* **Causa:** El sistema no puede procesar audio.
* **Soluci贸n:**
* *Windows:* `winget install Gyan.FFmpeg` y reinicia la terminal.
* *Docker:* Aseg煤rate de que el `Dockerfile` incluya `apt-get install -y ffmpeg`.



**2. Docker no conecta con Ollama**

* **Causa:** El contenedor no ve el `localhost` de tu PC.
* **Soluci贸n:** Usa siempre `-e OLLAMA_HOST=http://host.docker.internal:11434` al ejecutar el `docker run`.

**3. La transcripci贸n es lenta**

* **Causa:** Whisper est谩 usando la CPU.
* **Optimizaci贸n:** En `web_app_master.py`, cambia `MODELO_WHISPER = "small"` a `"base"` o `"tiny"` para mayor velocidad (menor precisi贸n).

---

Desarrollado como proyecto de Ingenier铆a de Sistemas para la gesti贸n de conocimiento acad茅mico y empresarial.

#### Edrem
#### Dios, la Patria y Assembly