# Local Audio RAG Assistant (Llama 3.2 + Whisper)

Un sistema de **GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG)** ejecutado 100% en local. Este proyecto permite transcribir archivos de audio (reuniones, clases, podcasts) y conversar con ellos utilizando Inteligencia Artificial, garantizando **privacidad total** y cero coste de API.

> **Arquitectura:** Audio â” Whisper (ETL) â” Embeddings (LanceDB) â” Ollama (Llama 3.2)

---

## Requisitos Previos

Para ejecutar este proyecto necesitas tener instalado en tu sistema:

* **Python 3.10+**
* **[Ollama](https://ollama.com/):** Motor de inferencia local.
* **[FFmpeg](https://ffmpeg.org/):** Necesario para el procesamiento de audio.
* **[AnythingLLM Desktop](https://useanything.com/):** Interfaz para gestiÃ³n de RAG y base de datos vectorial.

## InstalaciÃ³n

1. **Clonar el repositorio:**
```bash
git clone https://github.com/6Edgar9/local-audio-rag.git
cd local-audio-rag

```

2. **Crear entorno virtual (Opcional pero recomendado):**
```bash
python -m venv venv
# En Windows:
.\venv\Scripts\activate

```

3. **Instalar dependencias:**
```bash
pip install openai-whisper ollama

```

## GuÃ­a de Uso

### FASE 1: PreparaciÃ³n del Entorno

1. **Iniciar el Motor (Ollama):**
AsegÃºrate de que el servidor estÃ¡ escuchando en el puerto por defecto.
```bash
ollama serve

```

2. **Descargar/Verificar Modelo:**
Usamos `llama3.2` (3B) por ser eficiente para CPU/GPU integrada.
```bash
ollama run llama3.2
# Para verificar que estÃ¡ listo:
ollama list

```

3. **Verificar FFmpeg:**
Fundamental para que Whisper funcione.
```bash
ffmpeg -version

```


### FASE 2: ExtracciÃ³n de Datos (ETL)

Puedes usar el comando directo de Whisper, pero se recomienda usar el script `transcribir_pro.py` incluido en este repo para procesar mÃºltiples archivos y aÃ±adir **marcas de tiempo**.

**OpciÃ³n A: Script Automatizado (Recomendado)**
Coloca tus archivos `.mp3` en la carpeta raÃ­z y ejecuta:

```bash
py transcribir_pro.py

```

*Esto generarÃ¡ archivos `.txt` en la carpeta `/base_conocimiento` con timestamps.*

Una alternativa menos potente es:

```bash
py transcribir.py

```
*Se recomienda usar el primer script*

**OpciÃ³n B: Comando Manual**

```bash
whisper "nombre_audio.mp3" --model small --language es --output_format txt --initial_prompt "Una conversaciÃ³n"

```

### FASE 3: ConfiguraciÃ³n de la Suite (AnythingLLM)

1. **ConfiguraciÃ³n del Proveedor (Setup Inicial):**
* Ve a **Settings** (tuerca) â” **AI Providers** â” **LLM**.
* **Provider:** Ollama.
* **URL:** `http://127.0.0.1:11434`.
* **Model:** `llama3.2:latest`.
* **Max Tokens:** 4096 (Recomendado para 16GB RAM).


2. **Base de Datos Vectorial:**
* Ve a **Vector Database** y selecciona **LanceDB** (Local).


3. **Ingesta de Datos ("Entrenamiento"):**
* Crea un nuevo **Workspace** (ej: `Proyecto_Inicial`).
* Sube los archivos `.txt` generados en la Fase 2.
* Haz clic en **"Move to Workspace"**.
* Haz clic en **"Save and Embed"**.
* *Espera a que finalice el proceso de vectorizaciÃ³n.*

### FASE 4: InteracciÃ³n (Chat)

Ahora puedes interrogar a tus audios.

**Ejemplos de Prompts:**

* *"Resume los puntos clave de la reuniÃ³n basÃ¡ndote en el audio."*
* *"Â¿QuÃ© dijo la Persona A sobre el presupuesto? Cita el minuto exacto."*
* *"Identifica conclusiones tÃ©cnicas sobre la arquitectura del sistema."*

### Alternativa*

Para la ejecuciÃ³n del chat y Prompts sobre los .txt de audios tambiÃ©n puedes ejecutar el script:

```bash
py chat_audio.py

```
*Te permite conversar con la IA sobre los archivos desde la terminal busca todos los archivos .txt y los carga en la RAM*

## Interfaz Web (Quipu AI)

Este proyecto incluye una interfaz grÃ¡fica moderna construida con Streamlit.

**CaracterÃ­sticas:**
* ğŸ’¬ **Chat Interactivo:** Con historial y respuestas en tiempo real.
* ğŸ§  **Memoria Selectiva:** Elige quÃ© documentos activar/desactivar en la barra lateral.
* ğŸ“º **YouTube Loader:** Descarga y transcribe videos automÃ¡ticamente.
* ğŸ—£ï¸ **Respuesta de Voz:** TTS Neural con acentos regionales (Colombia, PerÃº, MÃ©xico, EspaÃ±a).

**EjecuciÃ³n:**
```bash
streamlit run web_app_master.py
```

### Estructura del Proyecto
AsegÃºrate de que tu carpeta se vea asÃ­ antes de subir el Ãºltimo commit a GitHub:

```text
ğŸ“‚ local-audio-rag/
â”‚
â”œâ”€â”€ ğŸ“‚ base_conocimiento/      # (Tus .txt)
â”œâ”€â”€ ğŸ“‚ temp_uploads/           # (Temporales)
â”‚
â”œâ”€â”€ web_app_master.py          # AplicaciÃ³n principal
â”œâ”€â”€ requirements.txt           # Lista de dependencias
â”œâ”€â”€ README.md
â”œâ”€â”€ transcribir_pro.py
â”œâ”€â”€ transcribir.py
â”œâ”€â”€ chat_audio.py
â””â”€â”€ .gitignore


```

## Notas TÃ©cnicas

* **Hardware:** Probado en Intel i7 (12Âª Gen) + 16GB RAM + Intel Iris Xe.
* **Modelos:** Se utiliza `whisper-small` para transcripciÃ³n y `llama3.2-3b` para inferencia, optimizados para ejecutarse sin GPU dedicada.
* **Privacidad:** Todos los datos se procesan localmente (On-Premise). Nada se envÃ­a a la nube.

---

#### Edrem
#### Dios, la Patria y Assembly